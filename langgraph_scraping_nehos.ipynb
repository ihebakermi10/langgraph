{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihebakermi10/langgraph/blob/main/langgraph_scraping_nehos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U langchain_community tiktoken langchain-openai langchainhub chromadb langchain langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P018BWPtd0e4",
        "outputId": "3f34e969-87ae-4b14-b345-52be56e2abc1"
      },
      "id": "P018BWPtd0e4",
      "execution_count": 12,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.3)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.11/dist-packages (0.1.21)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.69)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.9)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (2.32.0.20241016)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.8)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.11.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.10)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.45.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain_community) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Wov4HgeBrFRM"
      },
      "id": "Wov4HgeBrFRM"
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xtDXwZhEd16M"
      },
      "id": "xtDXwZhEd16M",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0,api_key=OPENAI_API_KEY)\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "system = (\n",
        "    \"Vous êtes un évaluateur de contenu chargé de détecter si un document contient AU MOINS UNE de ces informations essentielles : \"\n",
        "    \"horaires d'ouverture (explicites ou implicites), prix/tarifs, menu/catalogue, localisation (adresse, repères géographiques) \"\n",
        "    \"ou email de contact. \\n\\n\"\n",
        "\n",
        "    \"**Consignes clés** :\\n\"\n",
        "    \"1. Répondez 'Oui' dès qu'UNE SEULE information est identifiée (même indirectement).\\n\"\n",
        "    \"2. Acceptez les formulations contextuelles (ex: 'ouvert jusqu'à minuit', 'menu à 15€', 'proche de la gare').\\n\"\n",
        "    \"3. Répondez 'Non' UNIQUEMENT si le document est totalement générique (ex: 'Nous offrons un service professionnel').\\n\\n\"\n",
        "\n",
        "    \"**Format de réponse** :\\n\"\n",
        "    \"- Si Oui : 'Oui [éléments détectés entre crochets]' (ex: Oui [horaires, prix])\\n\"\n",
        "    \"- Si Non : 'Non [raison en 3 mots]' (ex: Non [données absentes])\\n\\n\"\n",
        "\n",
        "    \"Priorisez la pertinence pratique plutôt que l'exhaustivité.\"\n",
        ")\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n \"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "docs = \"\"\"\n",
        "Restaurant La Belle Table\n",
        "Horaires d'ouverture :\n",
        "- Lundi à Vendredi : 11h30 - 14h30 / 19h - 23h\n",
        "- Samedi : 12h - 00h\n",
        "- Dimanche : Fermé\n",
        "\n",
        "\"\"\"\n",
        "print(retrieval_grader.invoke({ \"document\": docs}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wljr6dCd64L",
        "outputId": "486bf248-7466-469c-dc4f-179195cf24e1"
      },
      "id": "5wljr6dCd64L",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Nouveau modèle de sortie structurée pour le nettoyage\n",
        "class CleanedDocument(BaseModel):\n",
        "    \"\"\"Document nettoyé avec les éléments clés extraits.\"\"\"\n",
        "    menu: str | None = Field(default=None, description=\"Menu/catalogue détecté\")\n",
        "    prix: str | None = Field(default=None, description=\"Prix/tarifs mentionnés\")\n",
        "    localisation: str | None = Field(default=None, description=\"Adresse complète ou coordonnées GPS\")\n",
        "    email: str | None = Field(default=None, description=\"Email de contact\")\n",
        "    telephone: str | None = Field(default=None, description=\"Numéro de téléphone\")\n",
        "    metadata: dict = Field(default_factory=dict, description=\"Métadonnées complémentaires\")\n",
        "\n",
        "# Instanciation du LLM en utilisant la clé API\n",
        "llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\", temperature=0, api_key=OPENAI_API_KEY)\n",
        "structured_llm_cleaner = llm.with_structured_output(CleanedDocument)\n",
        "\n",
        "# Prompt d'extraction structurée\n",
        "system_cleaning = (\n",
        "    \"Vous êtes un assistant de nettoyage de documents. Extrayez et structurez les éléments suivants :\\n\"\n",
        "    \"1. Menu/Catalogue : Liste des plats/produits avec descriptions\\n\"\n",
        "    \"2. Prix : Tarifs spécifiques ou fourchettes de prix\\n\"\n",
        "    \"3. Localisation : Adresse exacte, points de repère ou coordonnées GPS\\n\"\n",
        "    \"4. Email : Adresse email professionnelle\\n\"\n",
        "    \"5. Téléphone : Numéro de contact formaté\\n\\n\"\n",
        "    \"**Règles d'extraction** :\\n\"\n",
        "    \"- Conservez les formats originaux pour les prix (ex: 'Entrées : 8-12€')\\n\"\n",
        "    \"- Pour les adresses, gardez le format complet (ex: '12 Rue du Marché, 75001 Paris')\\n\"\n",
        "    \"- Si un élément est absent, laissez le champ vide\\n\"\n",
        "    \"- Ajoutez dans metadata['elements_detectes'] la liste des éléments trouvés\\n\\n\"\n",
        "    \"Exemple de sortie :\\n\"\n",
        "    \"menu: 'Entrées\\\\n- Salade César (12€)\\\\nPlats\\\\n- Boeuf Bourguignon (24€)'\\n\"\n",
        "    \"prix: 'Comptez 25-40€ par personne'\\n\"\n",
        "    \"localisation: '12 Rue des Oliviers, Marseille'\\n\"\n",
        "    \"metadata: {{'elements_detectes': ['menu', 'prix', 'localisation']}}\"\n",
        ")\n",
        "\n",
        "clean_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_cleaning),\n",
        "    (\"human\", \"Document à nettoyer :\\n\\n{document}\\n\\nStructurez les éléments demandés :\")\n",
        "])\n",
        "\n",
        "document_cleaner = clean_prompt | structured_llm_cleaner\n",
        "\n",
        "doc_to_clean = \"\"\n",
        "result = document_cleaner.invoke({\"document\": doc_to_clean})\n",
        "\n",
        "# Affichage du résultat\n",
        "print(\"=== Document nettoyé ===\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_85N_i6Ld_jf",
        "outputId": "86c9c7ba-21df-4b16-93e1-a97ce7819cb9"
      },
      "id": "_85N_i6Ld_jf",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Document nettoyé ===\n",
            "menu='## Choisissez votre burger !\\n\\nToulouse Burger vous propose de commander votre burger à Emporter, à manger sur Place et aussi en Livraison. Réservez dès à présent votre burger maison !\\n\\n## Les Menus\\n\\nLe Menu est composé du burger, des frites OU beignets d’oignons, de la sauce choisie et de la boisson.\\n\\n_Supplément Steak : 3,00€_\\n\\n_Supplément Chicken : 3,00€_\\n\\n_Supplément Galette : 2,50€_\\n\\nBURGER SIMPLE : 10€ (et 10,50€ en livraison)\\n\\nMENU SIMPLE : 15,50€\\n\\n## Nos burgers\\n\\n**Le Burger du Moment**\\n\\nDemandez la recette du mois\\n\\n**Le Classique** _(avec ou sans bacon)_\\n\\nSteak, Cheddar, Salade, Tomate, Oignons Rouges, Cornichons, Mayonnaise et Ketchup\\n\\n**Le Fred**_(création d’un client)_\\n\\nSteak, Tomme des Pyrénées, Mayonnaise au Piment d’Espelette Maison, Galette de Pomme de Terre, Confiture de Cerise Noire\\n\\n**Le Végétarien**\\n\\nTous nos burgers peuvent se transformer en Végétarien. Nous remplaçons le steak par une des trois galettes végétariennes de votre choix.\\n\\n**Le Vegan**\\n\\nGalette de Pomme de Terre, Salade, Tomate\\n\\nSauce au choix: _Ketchup, BBQ, Rougail Maison,_ _Chili Maison, Moutarde, Confiture de Cerise Noire_3 Légumes au choix: _Caviar d’Aubergine, Poivrons Grillés, Avocat, Champignons, Cornichons, Beignets d’Oignons, Oignons Rouges ou Oignons Frits_\\n\\n**Le Chicken**\\n\\nPoulet Pané, Cheddar, Oignons Rouges, Tomate, Salade, Sauce Béarnaise maison\\n\\n_\\\\*Tous nos burgers existent en version Halal en remplaçant la viande par du Chicken Halal._\\n\\n**Le Hot Fire**\\n\\nSteak, Emmental, Salade, Rougail Maison, Sauce Chili Maison\\n\\n**Le Toulouse Burger**\\n\\nSaucisse de Toulouse, Tomme des Pyrénées, Salade, Tomate, Oignons Frits, Sauce Barbecue\\n\\n**Le Capitole**\\n\\nSteak, Poitrine Fumée, Cheddar, Tomate, Salade, Champignons et oignons sautés à la moutarde, Sauce au Poivre Maison\\n\\n**Le Marengo**\\n\\nGalettes de Pomme de Terre, jambon, Poitrine Fumée, Reblochon, oignons frits, Crème Fraiche à l’Ail\\n\\n**L’Esquirol**\\n\\nSteak, Cheddar, Raclette, Chèvre Frais, Salade, Sauce Roquefort Maison\\n\\n**Le Péri**\\n\\nSteak, Emmental, Oeuf au Plat, Oignons Rouges, Poitrine Fumée, Salade, Tomate, Sauce Barbecue\\n\\n**Le Jaurès** Steak, Poitrine Fumée, Cheddar, Tomate, Salade, Nachos, Avocat, Sauce Chili\\n\\n**Le Carmes**\\n\\nSteak, Chèvre Frais, Tomates Cerise, Salade, Poivrons Grillés, Sauce Chili Maison\\n\\n**Le Patte d’oie**\\n\\nMagret de Canard, Salade, Tomates Cerises, Confit d’Oignons, Sauce Roquefort Maison\\n\\n## Nos Salades\\n\\n|     |     |\\n| --- | --- |\\n| Sur place /<br>à emporter | Livraison |\\n| 12,50€ | 13,50€ |\\n\\n**Saint Pierre**\\n\\nSalade, Tomates cerises, Oignons Frits, Œuf au plat, Champignons, Galette de Pommes de terre, Emmental, Poivrons, Avocat\\n\\n**Gourmande**\\n\\nSalade, Tomates cerises, Œuf au plat, Lardons grillés, Oignons, Noix\\n\\n**Terroir**\\n\\nSalade, Tomates cerises, Oignons Frits, Œuf au plat, Chicken, Bouchées Camembert\\n\\n## Nos Tapas\\n\\n|     |     |     |\\n| --- | --- | --- |\\n|  | Sur place /<br>à emporter | Livraison |\\n| **Frites maison**<br>simple | 4,00€ | 4,50€ |\\n| **Frites maison**<br>double | 5,50€ | 6,00€ |\\n| **Nuggets, Chili-Cheese, Mozzarella Sticks, Bouchées Camembert, Wings** | _Par 6_<br>5,50€ – 6,00€ | _Par 10_<br>8,50€ – 9,00€ |\\n| **Beignets d’oignons** | 4,00€ – 4,50€ | 7,00€ – 7,50€ |\\n\\n## Nos wraps\\n\\n|     |     |\\n| --- | --- |\\n| Sur place /<br>à emporter | Livraison |\\n| 10€ | 10,50€ |\\n\\n**Fromage**\\n\\nTortilla de Blé, Salade, Tomate, Cheddar, Emmental, Chèvre, Sauce Roquefort\\n\\n**Saint Aubin**\\n\\nTortilla de Blé, Salade, Tomate, Cheddar, Oignons Rouges, Galette de Pomme de Terre, Sauce Béarnaise\\n\\n**Spicy**\\n\\nTortilla de Blé, Salade, Tomate, Cheddar, Poitrine Fumée, Sauce Chili, Chicken, Oignons Rouges\\n\\n**Poulet**\\n\\nTortilla de Blé, Salade, Tomate, Cheddar, Ketchup, Mayonnaise, Chicken, Oignons Rouges\\n\\n## Nos desserts maison\\n\\n|     |     |     |\\n| --- | --- | --- |\\n|  | Sur place /<br>à emporter | Livraison |\\n| **Banoffee** | 4,00€ | 4,30€ |\\n| **Cookie** | 3,10€ | 3,60€ |\\n| **Cookie**<br>au beurre de cacahuète | 3,10€ | 3,60€ |\\n| **Brownie** | 4,00€ | 4,10€ |\\n\\n## Nos smoothies & Milkshake\\n\\n|     |     |     |\\n| --- | --- | --- |\\n|  | Sur place /<br>à emporter | Livraison |\\n| **Smoothie Fruits Rouges** | 4,50€ | 5,00€ |\\n| **Smoothie Exotique** | 4,50€ | 5,00€ |\\n| **Milkshake Banane** | 5,00€ | 5,50€ |\\n\\n## Nos Glaces\\n\\n|     |     |     |\\n| --- | --- | --- |\\n|  | Sur place /<br>à emporter | Livraison |\\n| **Ben and Jerry’s** 100ml | 4,00€ | 4,50€ |\\n| **Ben and Jerry’s** 500ml | 9,50€ | 10,00€ |\\n| **Glaces artisanales** 120ml | 4,00€ | 4,50€ |\\n\\n## Nos Boissons\\n\\n|     |     |\\n| --- | --- |\\n| **Ice Tea** | 3,00€ |\\n| **Coca** | 3,00€ |\\n| **Coca Zéro** | 3,00€ |\\n| **Orangina** | 3,00€ |\\n| **Jus – Pomme, Orange, Fraise** | 3,00€ |\\n| **Eau plate** | 3,00€ |\\n| **Perrier** | 3,00€ |\\n| **Bière pression artisanale** | 4,00€ |\\n| **Bière en bouteille** | 5,00€ |\\n| **Kumbucha** | 4,00€ |' prix='BURGER SIMPLE : 10€ (et 10,50€ en livraison)\\nMENU SIMPLE : 15,50€\\n_Supplément Steak : 3,00€_\\n_Supplément Chicken : 3,00€_\\n_Supplément Galette : 2,50€_\\n_Supplément Frites : 1,50€_\\n| Menu Kids | 11,50€ | 13,50€ |\\n| Menu Étudiant | 13€ | 15€ |\\n| **Frites maison**<br>simple | 4,00€ | 4,50€ |\\n| **Frites maison**<br>double | 5,50€ | 6,00€ |\\n| **Nuggets, Chili-Cheese, Mozzarella Sticks, Bouchées Camembert, Wings** | _Par 6_<br>5,50€ – 6,00€ | _Par 10_<br>8,50€ – 9,00€ |\\n| **Beignets d’oignons** | 4,00€ – 4,50€ | 7,00€ – 7,50€ |\\n| **Banoffee** | 4,00€ | 4,30€ |\\n| **Cookie** | 3,10€ | 3,60€ |\\n| **Cookie**<br>au beurre de cacahuète | 3,10€ | 3,60€ |\\n| **Brownie** | 4,00€ | 4,10€ |\\n| **Smoothie Fruits Rouges** | 4,50€ | 5,00€ |\\n| **Smoothie Exotique** | 4,50€ | 5,00€ |\\n| **Milkshake Banane** | 5,00€ | 5,50€ |\\n| **Ben and Jerry’s** 100ml | 4,00€ | 4,50€ |\\n| **Ben and Jerry’s** 500ml | 9,50€ | 10,00€ |\\n| **Glaces artisanales** 120ml | 4,00€ | 4,50€ |\\n| **Ice Tea** | 3,00€ |\\n| **Coca** | 3,00€ |\\n| **Coca Zéro** | 3,00€ |\\n| **Orangina** | 3,00€ |\\n| **Jus – Pomme, Orange, Fraise** | 3,00€ |\\n| **Eau plate** | 3,00€ |\\n| **Perrier** | 3,00€ |\\n| **Bière pression artisanale** | 4,00€ |\\n| **Bière en bouteille** | 5,00€ |\\n| **Kumbucha** | 4,00€ |' localisation='29 Rue Gabriel Péri, 31000 Toulouse' email='toulouseburgertoulouse@yahoo.com' telephone='05 61 13 11 31' metadata={'elements_detectes': ['menu', 'prix', 'localisation', 'email', 'telephone']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "class GradeInformationLoss(BaseModel):\n",
        "    \"\"\"\n",
        "    Ce modèle renvoie un score binaire indiquant si le document nettoyé\n",
        "    conserve toutes les informations pertinentes de l'original.\n",
        "\n",
        "    binary_score:\n",
        "        - 'yes' : Le document nettoyé conserve toutes les informations essentielles.\n",
        "        - 'no' : Des informations importantes ont été perdues lors du nettoyage.\n",
        "    \"\"\"\n",
        "    binary_score: str = Field(\n",
        "        description=\"Indique si le document nettoyé conserve les infos pertinentes ('yes') ou non ('no')\"\n",
        "    )\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_API_KEY)\n",
        "structured_llm_checker = llm.with_structured_output(GradeInformationLoss)\n",
        "\n",
        "system_prompt = (\n",
        "    \"Vous êtes un évaluateur qui doit comparer un document original et sa version nettoyée. \"\n",
        "    \"Votre tâche est de déterminer si le document nettoyé conserve toutes les informations essentielles \"\n",
        "    \"(menu, prix, localisation, email, téléphone, etc.) présentes dans l'original. \\n\\n\"\n",
        "    \"Si le document nettoyé contient bien toutes les informations nécessaires, répondez par 'yes'. \"\n",
        "    \"Sinon, si certaines informations importantes manquent, répondez par 'no'.\"\n",
        ")\n",
        "\n",
        "grading_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"Document original :\\n\\n{original_document}\\n\\nDocument nettoyé :\\n\\n{cleaned_document}\\n\\n\"\n",
        "                \"Le document nettoyé conserve-t-il toutes les informations pertinentes ? Répondez 'yes' ou 'no'.\")\n",
        "])\n",
        "\n",
        "# Chaîne de vérification en combinant le prompt et le LLM structuré\n",
        "information_loss_checker = grading_prompt | structured_llm_checker\n",
        "\n",
        "# Exemple d'utilisation\n",
        "original_document = \"\"\"\n",
        "Restaurant La Belle Table\n",
        "Horaires d'ouverture :\n",
        "- Lundi à Vendredi : 11h30 - 14h30 / 19h - 23h\n",
        "- Samedi : 12h - 00h\n",
        "- Dimanche : Fermé\n",
        "\n",
        "Menu du Jour :\n",
        "Entrées :\n",
        "- Velouté de champignons (9€)\n",
        "- Salade de chèvre chaud (12€)\n",
        "\n",
        "Plats Principaux :\n",
        "- Boeuf Bourguignon (24€)\n",
        "- Daurade royale grillée (28€)\n",
        "\n",
        "Contact : reservation@labelletable.com - Tel: 04 91 12 34 56\n",
        "\n",
        "Adresse : 12 Cours Honoré d'Estienne d'Orves, 13001 Marseille\n",
        "\"\"\"\n",
        "\n",
        "cleaned_document = \"\"\"\n",
        "Restaurant La Belle Table\n",
        "\n",
        "Menu du Jour :\n",
        "- Velouté de champignons (9€)\n",
        "- Salade de chèvre chaud (12€)\n",
        "- Boeuf Bourguignon (24€)\n",
        "- Daurade royale grillée (28€)\n",
        "\n",
        "Contact : reservation@labelletable.com\n",
        "\n",
        "Adresse : 12 Cours Honoré d'Estienne d'Orves, 13001 Marseille\n",
        "\"\"\"\n",
        "\n",
        "result = information_loss_checker.invoke({\n",
        "    \"original_document\": original_document,\n",
        "    \"cleaned_document\": cleaned_document\n",
        "})\n",
        "\n",
        "print(\"Score de conservation des informations :\", result.binary_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lYh2L3dlp2m",
        "outputId": "f21bc0b0-c4ab-4280-b0c9-60a3bdd48f07"
      },
      "id": "3lYh2L3dlp2m",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score de conservation des informations : no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "\n",
        "# Modèle de sortie pour la réécriture d'un document\n",
        "class DocumentRewriterOutput(BaseModel):\n",
        "    \"\"\"\n",
        "    Ce modèle renvoie le document réécrit avec toutes les informations essentielles complétées.\n",
        "\n",
        "    rewritten_document:\n",
        "        Le document réécrit contenant le menu complet, les tarifs, les coordonnées et l'adresse.\n",
        "    \"\"\"\n",
        "    rewritten_document: str = Field(\n",
        "        description=\"Document réécrit après complétion des informations manquantes\"\n",
        "    )\n",
        "\n",
        "# Instanciation du LLM avec la clé API\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_API_KEY)\n",
        "structured_llm_rewriter = llm.with_structured_output(DocumentRewriterOutput)\n",
        "\n",
        "# Définition du prompt de réécriture\n",
        "system_prompt = (\n",
        "    \"Vous êtes un assistant spécialisé dans la réécriture de documents de restaurant. \"\n",
        "    \"Votre tâche est de prendre un document nettoyé qui pourrait manquer d'informations essentielles \"\n",
        "    \"telles que le menu complet, les prix, les coordonnées (email, téléphone) et l'adresse, \"\n",
        "    \"et de le réécrire en complétant ces éléments manquants de manière cohérente et naturelle. \\n\\n\"\n",
        "    \"Assurez-vous de conserver le style et la structure du document tout en ajoutant les informations nécessaires.\"\n",
        ")\n",
        "\n",
        "rewrite_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", \"Document nettoyé incomplet :\\n\\n{document}\\n\\nRéécrivez le document en ajoutant toutes les informations essentielles (menu complet, tarifs, coordonnées, adresse) si elles manquent.\")\n",
        "])\n",
        "\n",
        "# Chaîne de réécriture combinant le prompt, le LLM et le parser de sortie\n",
        "document_rewriter = rewrite_prompt | structured_llm_rewriter\n",
        "\n",
        "# Exemple d'utilisation\n",
        "doc_clean = \"\"\"\n",
        "Restaurant La Belle Table\n",
        "\n",
        "Menu du Jour :\n",
        "- Velouté de champignons (9€)\n",
        "- Salade de chèvre chaud (12€)\n",
        "- Boeuf Bourguignon (24€)\n",
        "- Daurade royale grillée (28€)\n",
        "\n",
        "Contact : reservation@labelletable.com\n",
        "\n",
        "Adresse : 12 Cours Honoré d'Estienne d'Orves, 13001 Marseille\n",
        "\"\"\"\n",
        "\n",
        "result = document_rewriter.invoke({\"document\": doc_clean})\n",
        "\n",
        "print(\"=== Document réécrit ===\")\n",
        "print(result.rewritten_document)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPYdcHCOrCUx",
        "outputId": "1e93d60d-6b4a-4ed9-f0a4-22f479856794"
      },
      "id": "dPYdcHCOrCUx",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Document réécrit ===\n",
            "Restaurant La Belle Table\n",
            "\n",
            "Menu du Jour :\n",
            "- Velouté de champignons (9€)\n",
            "- Salade de chèvre chaud (12€)\n",
            "- Boeuf Bourguignon (24€)\n",
            "- Daurade royale grillée (28€)\n",
            "\n",
            "Contact : reservation@labelletable.com\n",
            "Téléphone : +33 6 12 34 56 78\n",
            "\n",
            "Adresse : 12 Cours Honoré d'Estienne d'Orves, 13001 Marseille\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "# Instanciation du LLM (GPT-3.5-turbo ici)\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_API_KEY)\n",
        "\n",
        "###############################################################################\n",
        "# 1️⃣ Classe de stockage de texte\n",
        "###############################################################################\n",
        "\n",
        "class StoreTextOutput(BaseModel):\n",
        "    \"\"\"\n",
        "    Modèle de sortie pour le stockage de texte.\n",
        "\n",
        "    stored_text:\n",
        "        Le texte tel qu'il a été stocké.\n",
        "    \"\"\"\n",
        "    stored_text: str = Field(..., description=\"Texte stocké avec succès\")\n",
        "\n",
        "store_text_system = (\n",
        "    \"Vous êtes un assistant de stockage de texte. Vous recevez un texte et vous devez le renvoyer tel quel \"\n",
        "    \"dans le format JSON suivant : {{'stored_text': 'votre texte ici'}}.\"\n",
        ")\n",
        "store_text_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", store_text_system),\n",
        "    (\"human\", \"Veuillez stocker le texte suivant :\\n\\n{text}\")\n",
        "])\n",
        "\n",
        "store_text_chain = store_text_prompt | llm.with_structured_output(StoreTextOutput)\n",
        "\n",
        "input_text = \"Ceci est le texte à stocker dans la variable.\"\n",
        "result_store = store_text_chain.invoke({\"text\": input_text})\n",
        "print(\"=== Résultat du stockage ===\")\n",
        "print(result_store)\n",
        "print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RpUteUqrvmg",
        "outputId": "9a4cbd90-db71-4931-82da-70e109b908c0"
      },
      "id": "2RpUteUqrvmg",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Résultat du stockage ===\n",
            "stored_text='Ceci est le texte à stocker dans la variable.'\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Résultat de la vérification ===\n",
            "exists='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class VerifyDataOutput(BaseModel):\n",
        "    \"\"\"\n",
        "    Modèle de sortie pour la vérification de présence de données.\n",
        "\n",
        "    exists:\n",
        "        'yes' si la donnée figure dans la base, 'no' sinon.\n",
        "    \"\"\"\n",
        "    exists: str = Field(..., description=\"Indique si la donnée existe dans la base ('yes' ou 'no')\")\n",
        "\n",
        "verify_data_system = (\n",
        "    \"Vous êtes un assistant chargé de vérifier si une donnée donnée existe dans une base de données. \"\n",
        "    \"La base de données est fournie sous forme d'une liste d'éléments (texte). \"\n",
        "    \"Si la donnée figure dans la base, répondez 'yes'. Sinon, répondez 'no'.\"\n",
        ")\n",
        "verify_data_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", verify_data_system),\n",
        "    (\"human\", \"Donnée à vérifier : {data}\\nBase de données : {database}\\n\"\n",
        "                \"La donnée existe-t-elle dans la base ? Répondez 'yes' ou 'no'.\")\n",
        "])\n",
        "\n",
        "verify_data_chain = verify_data_prompt | llm.with_structured_output(VerifyDataOutput)\n",
        "\n",
        "# Exemple d'utilisation de la chaîne de vérification\n",
        "data_to_check = \"Ceci est le texte à stocker dans la variable.\"  # On vérifie le même texte\n",
        "# Simulation d'une base de données sous forme de liste\n",
        "database = [\n",
        "    \"Autre texte\",\n",
        "    \"Ceci est le texte à stocker dans la variable.\",\n",
        "    \"Texte supplémentaire\"\n",
        "]\n",
        "\n",
        "result_verify = verify_data_chain.invoke({\"data\": data_to_check, \"database\": database})\n",
        "print(\"=== Résultat de la vérification ===\")\n",
        "print(result_verify)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNGIjPGt_i8",
        "outputId": "564798ff-3d45-4455-bdc1-165020038769"
      },
      "id": "HgNGIjPGt_i8",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1362: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Résultat de la vérification ===\n",
            "exists='yes'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FFrzpoY-urUQ"
      },
      "id": "FFrzpoY-urUQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}